{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that takes iterates over all files and produces a concatenated dataframe\n",
    "#### Data produced will be stored in DataFrame named as 'finalDataFrame' that will persist across Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import time # workaround to get past the issue of Google Sheets API timing out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve filesInDriveDict\n",
    "%store -r filesInDriveDict\n",
    "\n",
    "# Configure the connection \n",
    "scopes = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive.readonly']\n",
    "key_file_location = 'gsheetsprivkey\\serviceaccount.json'\n",
    "\n",
    "# Give the path to the Service Account Credential json file \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(key_file_location,scopes)\n",
    "\n",
    "# Authorise your Jupyter Notebook to connect to Google Drive API using private key credentials in 'credentials'\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List comprehension to pull up all the ids from the filesInDriveDict\n",
    "fileKeyIDs = [val['id'] for key,val in filesInDriveDict.items()]\n",
    "\n",
    "#initialize a list with one value , viz number of files in fileKeyIDs\n",
    "fileIDChunkList = [len(fileKeyIDs)]\n",
    "\n",
    "# breaking 27 into [7,10,10]\n",
    "while fileIDChunkList[0] > 10:\n",
    "    fileIDChunkList.append(10)\n",
    "    fileIDChunkList[0] = fileIDChunkList[0]-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "# Note: this function is applied in context of each season\n",
    "# Add points for each team before the game starts\n",
    "def addPointsBeforeGame(pd_data):\n",
    "    #unique teams\n",
    "    uniqueTeams = pd_data['HomeTeam'].unique()\n",
    "\n",
    "    #build dict with all teams in that season; initialize to zero for each\n",
    "    teamPoints = {uniqueTeams[i]:0 for i in range(0,len(uniqueTeams))};\n",
    "    \n",
    "    # Adding new feature: Points before each game starts\n",
    "    # PBGH = PointsBeforeGameHomeTeam in that season\n",
    "    # PBGA = PointsBeforeGameAwaayTeam in that season\n",
    "    pd_data['PBGH'] = 0\n",
    "    pd_data['PBGA'] = 0\n",
    "\n",
    "    for index,row in pd_data.iterrows():\n",
    "        #set points before start of game into DataFrame\n",
    "        pd_data.loc[index,'PBGH'] = teamPoints[row['HomeTeam']]\n",
    "        pd_data.loc[index,'PBGA'] = teamPoints[row['AwayTeam']]\n",
    "        #check who won and who lost\n",
    "        if (row['FTR']=='D'):\n",
    "            teamPoints[row['HomeTeam']] += 1\n",
    "            teamPoints[row['AwayTeam']] += 1\n",
    "        elif (row['FTR']=='H'):\n",
    "            teamPoints[row['HomeTeam']] += 3\n",
    "        elif (row['FTR']=='A'):\n",
    "            teamPoints[row['AwayTeam']] += 3\n",
    "    return \n",
    "\n",
    "# Note: this function is applied in context of all seasons\n",
    "def populateCumulativeGoalsAndStreak(finalData):\n",
    "    \n",
    "    #across all seasons thus far\n",
    "    uniqueTeams = finalData['HomeTeam'].unique()\n",
    "    \n",
    "    #build dict with ALL teams; initialize to ----- for each\n",
    "    teamStreak = {uniqueTeams[i]: {'GS': 0,'GC':0,'Streak':'----'} for i in range(0,len(uniqueTeams))}; \n",
    "    \n",
    "    # Adding new feature: Win streak before game\n",
    "    # HomeStreak = Streak of home team before the game\n",
    "    # AwayStreak = Streak of away team before the game\n",
    "    # initialize to null initial value\n",
    "    finalData['HomeStreak'] = ''\n",
    "    finalData['AwayStreak'] = ''\n",
    "    finalData['HTGS'] = 0\n",
    "    finalData['HTGC'] = 0\n",
    "    finalData['ATGS'] = 0\n",
    "    finalData['ATGC'] = 0\n",
    "\n",
    "        \n",
    "    for index,row in finalData.iterrows():\n",
    "    \n",
    "        #Populate streak data into columns before game outcome is counted\n",
    "        finalData.at[index,'HomeStreak'] = teamStreak[row['HomeTeam']]['Streak'];\n",
    "        finalData.at[index,'AwayStreak'] = teamStreak[row['AwayTeam']]['Streak'];\n",
    "        finalData.at[index,'HTGS'] = teamStreak[row['HomeTeam']]['GS'];\n",
    "        finalData.at[index,'ATGS'] = teamStreak[row['AwayTeam']]['GS'];\n",
    "        finalData.at[index,'HTGC'] = teamStreak[row['HomeTeam']]['GC'];\n",
    "        finalData.at[index,'ATGC'] = teamStreak[row['AwayTeam']]['GC'];\n",
    "\n",
    "        teamStreak[row['HomeTeam']]['GS'] += int(row['FTHG'])\n",
    "        teamStreak[row['AwayTeam']]['GC'] += int(row['FTHG'])\n",
    "        teamStreak[row['AwayTeam']]['GS'] += int(row['FTAG'])\n",
    "        teamStreak[row['HomeTeam']]['GC'] += int(row['FTAG'])\n",
    "\n",
    "        #check who won and who lost\n",
    "        if (row['FTR']=='Draw'):\n",
    "            teamStreak[row['HomeTeam']]['Streak'] = 'D' + teamStreak[row['HomeTeam']]['Streak']\n",
    "            teamStreak[row['AwayTeam']]['Streak'] = 'D' + teamStreak[row['AwayTeam']]['Streak']\n",
    "        elif (row['FTR']=='Home'):\n",
    "            teamStreak[row['HomeTeam']]['Streak'] = 'W' + teamStreak[row['HomeTeam']]['Streak']\n",
    "            teamStreak[row['AwayTeam']]['Streak'] = 'L' + teamStreak[row['AwayTeam']]['Streak']\n",
    "        elif (row['FTR']=='Away'):\n",
    "            teamStreak[row['HomeTeam']]['Streak'] = 'L' + teamStreak[row['HomeTeam']]['Streak']\n",
    "            teamStreak[row['AwayTeam']]['Streak'] = 'W' + teamStreak[row['AwayTeam']]['Streak']\n",
    "\n",
    "        #snipping off last character since above if block added a result to start\n",
    "        teamStreak[row['HomeTeam']]['Streak'] = teamStreak[row['HomeTeam']]['Streak'][0:-1]\n",
    "        teamStreak[row['AwayTeam']]['Streak'] = teamStreak[row['AwayTeam']]['Streak'][0:-1]\n",
    "\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize new DataFrame\n",
    "finalDataFrame = pd.DataFrame()\n",
    "\n",
    "#variables used to split fileKeyIDs. Using this method to prevent Google API rejections\n",
    "start = end = 0\n",
    "\n",
    "# Expected to take over 100 seconds per 10 files due to time.sleep(). Expect 30 files to take 300 seconds (i.e. 5 mins)\n",
    "for item in fileIDChunkList:\n",
    "    end = start + item\n",
    "    for keyID in fileKeyIDs[start:end]:\n",
    "        #spreadsheet_key is the internal key stored in Google drive for that file\n",
    "        tempWorkbook = gc.open_by_key(keyID)\n",
    "        #By default load 1st sheet of the workbook , i.e. index = 0\n",
    "        tempSheet = tempWorkbook.get_worksheet(0)\n",
    "        #get_all_values returns list of lists with first list as column headers\n",
    "        tempValues = tempSheet.get_all_values()\n",
    "        # Pulling the data and transform it to the data frame .1st row is header , remaining are actual values\n",
    "        temp_pd_data = pd.DataFrame(tempValues[1:], columns = tempValues[0])\n",
    "        #converting string format dates to datetime object\n",
    "        temp_pd_data['Date'] = pd.to_datetime(temp_pd_data['Date'])\n",
    "        addPointsBeforeGame(temp_pd_data)\n",
    "        #iteratively concatenating\n",
    "        finalDataFrame = pd.concat([finalDataFrame,temp_pd_data])\n",
    "    start += item;\n",
    "    #if not on the last item (since 'end' is equal to length of fileKeyIDs on last step), proceed to pause for 100 secs\n",
    "    if end < len(fileKeyIDs):\n",
    "        time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort rows by date ascending\n",
    "finalDataFrame.sort_values(by='Date',inplace=True)\n",
    "\n",
    "#numbered index with unique numbers\n",
    "finalDataFrame['newIndex'] = range(0,len(finalDataFrame.index))\n",
    "finalDataFrame.set_index(['newIndex'],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "populateCumulativeGoalsAndStreak(finalDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'finalDataFrame' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store finalDataFrame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
